\documentclass[12pt, a4paper]{article}

% --- Configurações de Pacotes ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[portuguese]{babel}
\usepackage{amsmath, amssymb} % Para fórmulas matemáticas avançadas
\usepackage{geometry} % Para configurar margens
\usepackage{listings} % Para incluir código-fonte
\usepackage{hyperref} % Para links e referências
\usepackage{tocloft} % Para personalizar o Sumário
\usepackage{xcolor} % Para cores no listings
\usepackage{indentfirst} % Para indentar o primeiro parágrafo
\usepackage{setspace} % Para controle de espaçamento
\usepackage{booktabs} % Pacote para tabelas profissionais
\usepackage{float} % Necessário para o posicionamento [H] de tabelas

% --- Configuração da Geometria (Margens ABNT - Padrão 3/3/2/2) ---
\geometry{
    a4paper,
    top=3cm,
    bottom=2cm,
    left=3cm,
    right=2cm,
    headheight=15pt,
    includeheadfoot
}

% --- Configuração de Espaçamento e Formato ---
\setlength{\parindent}{1.5cm} % Indentação de parágrafo
\onehalfspacing % Espaçamento de 1,5 entre linhas (padrão ABNT)

% --- Configuração da Listagem de Código (Python) ---
\lstset{
    language=Python,
    basicstyle=\small\ttfamily,
    keywordstyle=\color{blue!80!black},
    stringstyle=\color{red!70!black},
    commentstyle=\color{gray}\textit,
    showstringspaces=false,
    breaklines=true,
    frame=single,
    frameround=tttt,
    rulesepcolor=\color{gray},
    numbers=left,
    numberstyle=\tiny\color{gray},
    captionpos=b,
    inputencoding=utf8
}

% --- Comando para Espaçamento ABNT (Simulado: Proporcional 1/3, 2/3, 2cm) ---
\newcommand{\abntvspace}{\vspace*{1.5cm}} % Espaçamento padrão para blocos
\renewcommand\cftsecleader{\cftdotfill{\cftdotsep}}

\begin{document}

% -------------------------------
% --- CAPA (PÁGINA 1) - PADRÃO ABNT
% -------------------------------
\begin{titlepage}
    \centering
    \thispagestyle{empty}

    % Bloco 1: Autor
    \vspace*{4cm} % Espaçamento Superior para Centralização Vertical
    \textbf{\Large ADRIANE DA COSTA SANTOS}

    % --- Bloco 2: Título do Trabalho (Centralizado, Negrito, Caixa Alta) ---
\vspace*{6cm} % Espaço antes do título (ajuste conforme desejar)

\begin{center}
    {\bfseries\LARGE SISTEMA DE RECUPERAÇÃO DE INFORMAÇÃO SEMÂNTICA}\\[0.2cm]
    {\bfseries\LARGE DE NOTÍCIAS DE CRIPTOMOEDAS}
    {\bfseries\LARGE BASEADO EM TF-IDF}
\end{center}

\vspace*{2cm} % Espaço depois do título
    % Bloco 3: Local e Data (Inferior da Página)
    \vfill % Preenche o espaço restante
    \textbf{\large SANTOS} \\
    \textbf{\large 2025}

\end{titlepage}

\clearpage

% -------------------------------
% --- FOLHA DE ROSTO (PÁGINA 2) - PADRÃO ABNT
% -------------------------------
\begin{titlepage}
    \centering
    \thispagestyle{empty}

    % Bloco 1: Autor
    \vspace*{4cm} % Espaçamento Superior para Centralização Vertical
    \textbf{\Large ADRIANE DA COSTA SANTOS}

    % Bloco 2: Título do Trabalho
    \abntvspace
    \abntvspace
    \begin{center}
    {\bfseries\LARGE SISTEMA DE RECUPERAÇÃO DE INFORMAÇÃO SEMÂNTICA}\\[0.02cm]
    {\bfseries\LARGE DE NOTÍCIAS DE CRIPTOMOEDAS}
    {\bfseries\LARGE BASEADO EM TF-IDF}
\end{center}

    % Bloco 3: Natureza do Trabalho (Recuo ABNT: Inserir com ambiente 'minipage')
    \abntvspace
    \begin{minipage}{0.6\textwidth} % Recuo de 7,5cm da margem (simulado)
        \raggedright
        Relatório Técnico-Científico apresentado como documento de formalização, detalhamento metodológico e análise do projeto de motor de busca semântica, utilizando o algoritmo Term Frequency-Inverse Document Frequency (TF-IDF).
    \end{minipage}

    % Bloco 4: Local e Data (Inferior da Página)
    \vfill % Preenche o espaço restante
    \textbf{\large SANTOS} \\
    \textbf{\large 2025}
\end{titlepage}

\clearpage
\pagenumbering{roman} % Páginas iniciais em números romanos (Sumário)

% --- SUMÁRIO ---
\section*{Sumário}
\addcontentsline{toc}{section}{Sumário}
\tableofcontents

\clearpage
\pagenumbering{arabic} % Conteúdo principal em números arábicos

% -------------------------------
% --- 1. INTRODUÇÃO (EXPANDIDA) ---
% -------------------------------
\section{Introdução}

O ecossistema de criptoativos, notável pela intensa volatilidade e um fluxo contínuo de inovação, gera diariamente um volume massivo e crescente de informações. A recuperação eficiente e semanticamente precisa dessas notícias é um requisito fundamental para a sustentação de decisões informadas por parte de investidores e analistas. Este Relatório Técnico-Científico tem como objetivo principal detalhar o desenvolvimento, a arquitetura e a avaliação de um motor de busca semântica, o qual foi especificamente calibrado para indexar e consultar um Corpus restrito de notícias do setor, representado pelo dataset \texttt{cripto\_noticias(1).csv}.

O desenvolvimento está fundamentado na aplicação do algoritmo TF-IDF (Term Frequency-Inverse Document Frequency), uma das abordagens mais estabelecidas e de maior robustez no campo do Processamento de Linguagem Natural (PLN) e da Recuperação da Informação (RI). A contribuição central do sistema reside em sua capacidade de transpor dados textuais para o espaço vetorial, atribuindo uma ponderação estatística a cada termo. Este peso é uma função da relevância local do termo no documento específico, balanceada por sua raridade no Corpus completo \cite{silva2020mining, almeida2021pln}.

\subsection{Estrutura do Relatório}
O presente documento está organizado de forma a prover uma análise completa, desde a fundamentação teórica até a comprovação empírica dos resultados. A Seção 2 delineia o arcabouço matemático do TF-IDF e da Similaridade de Cosseno. A Seção 3 contém a caracterização e a análise detalhada do Corpus de dados. A Seção 4 discorre sobre a implementação técnica do código Python. Por fim, a Seção 5 apresenta e discute os resultados empíricos obtidos na validação do sistema, seguida da Conclusão.

% -------------------------------
% --- 2. METODOLOGIA: TF-IDF (EXPANDIDA) ---
% -------------------------------
\section{Metodologia: Fundamentação Teórica do TF-IDF e Similaridade}

O êxito do sistema de busca é intrinsecamente ligado à aplicação rigorosa do Modelo Vetorial, no qual o TF-IDF opera como o esquema de ponderação central. Esta metodologia é essencial, pois permite a transformação de dados textuais desestruturados em vetores numéricos de alta dimensionalidade, viabilizando o cálculo de métricas de distância e similaridade que refletem o conteúdo semântico.

\subsection{Cálculo da Ponderação TF-IDF}

O peso final ($w_{i,j}$) de um termo ($i$) no documento ($j$) é uma medida composta que sintetiza sua relevância dentro do documento e sua especificidade dentro do Corpus. Este peso é obtido pelo produto da Frequência do Termo (TF) pela Frequência Inversa do Documento (IDF).

\subsubsection{Frequência do Termo (TF)}
A Frequência do Termo mensura a ocorrência do termo $i$ no documento $j$. Para prevenir que a extensão do documento cause um viés desproporcional no peso, é aplicada a normalização:
$$
\text{TF}_{i,j} = \frac{f_{i,j}}{\max_{k} f_{k,j}}
$$
Nesta formulação, $f_{i,j}$ representa a contagem absoluta do termo $i$ no documento $j$, e $\max_{k} f_{k,j}$ denota a frequência do termo de maior ocorrência no mesmo documento. Esta normalização garante que o peso do termo seja relativo à sua importância local, e não ao tamanho absoluto do texto.

\subsubsection{Frequência Inversa do Documento (IDF)}
O IDF quantifica o poder discriminatório do termo ao longo de todo o Corpus. Termos funcionais ou de alta frequência (como artigos e preposições) tendem a possuir um valor de IDF baixo.
$$
\text{IDF}_{i} = \log\left(\frac{N}{df_i}\right)
$$
Onde $N$ é o número total de documentos no Corpus e $df_i$ é o número de documentos em que o termo $i$ está presente. A aplicação do logaritmo é uma prática padrão para suavizar a escala e reduzir a influência de termos extremamente raros \cite{silva2020mining}.

O peso composto final, que estabelece a magnitude do termo no vetor, é definido como: $w_{i,j} = \text{TF}_{i,j} \times \text{IDF}_{i}$.

\subsection{Métrica de Similaridade de Cosseno}

Com o Corpus e a consulta vetorizados, a relevância da notícia em relação à busca é determinada pela Similaridade de Cosseno. Esta métrica é superior a métricas de distância (como a Distância Euclidiana) no contexto de RI, pois ela avalia a similaridade angular entre o vetor da consulta ($Q$) e o vetor do documento ($D$), ignorando a diferença de magnitude que seria causada pela diferença no tamanho dos documentos \cite{oliveira2023busca}.

$$
\text{Similaridade}(Q, D) = \frac{Q \cdot D}{\|Q\| \|D\|}
$$
A Similaridade de Cosseno mensura, portanto, a direção semântica dos vetores. O resultado é um valor normalizado no intervalo $[0, 1]$, onde valores mais próximos de 1 indicam maior similaridade temática e, consequentemente, maior relevância para a query inicial.

% -------------------------------
% --- 3. ANÁLISE DO CORPUS DE DADOS (EXPANDIDA) ---
% -------------------------------
\section{Análise do Corpus de Dados}

O Corpus, originário do arquivo \texttt{cripto\_noticias(1).csv}, abrange 98 documentos textuais. A especialização temática do Corpus em criptomoedas implica um vocabulário técnico que maximiza a performance do cálculo do IDF.

\subsection{Estrutura e Conteúdo}
O arquivo CSV apresenta uma estrutura de dados minimalista e suficiente para a vetorização. A coluna \texttt{id} é utilizada para referenciar unicamente cada documento, enquanto a coluna \texttt{texto} fornece o conteúdo primário que é submetido ao pipeline do Processamento de Linguagem Natural. A diversidade do Corpus abrange desde tópicos de governança e regulação (como a regulação de stablecoins no ID 9) até aspectos técnicos de segurança e escalabilidade (vulnerabilidades DeFi no ID 11) e impacto ambiental (mineração sustentável no ID 27).

\subsection{Impacto do Corpus no TF-IDF}
A especialização temática do Corpus é um elemento de projeto crucial. Ela garante que o TF-IDF não apenas distinga termos, mas também capture nuances conceituais específicas do setor. Por exemplo, a presença frequente de termos como "Bitcoin" ou "Ethereum" no Corpus naturalmente resultaria em um IDF mais baixo. Contudo, a raridade de termos combinados como "mineração sustentável" ou "conformidade regulatória" em relação a outros documentos especializados é preservada, garantindo que o algoritmo atribua pesos elevados a notícias que abordam temas específicos com profundidade. Sem um Corpus focalizado, a distinção semântica seria diluída.

% -------------------------------
% --- 4. IMPLEMENTAÇÃO E ANÁLISE DO CÓDIGO ---
% -------------------------------
\section{Implementação e Análise Detalhada do Código Python}

O sistema foi implementado via script \texttt{tfidf.py}, integrando eficientemente bibliotecas de Data Science e PLN. O framework \textbf{pandas} é empregado para a manipulação e ingestão do Corpus, enquanto a biblioteca scikit-learn provê as ferramentas de feature engineering e o mecanismo de cálculo da similaridade.

\subsection{Carregamento e Vetorização do Corpus}
A fase inicial do processamento consiste na leitura do Corpus e na subsequente construção da matriz de pesos TF-IDF, conforme ilustrado a seguir:

\begin{lstlisting}[caption=Inicialização e Treinamento do TfidfVectorizer (tfidf.py), label=lst:tfidf\_init]
# 1. Carregar dataset
df = pd.read_csv("cripto_noticias(1).csv")

# 2. Criar matriz TF-IDF
vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = vectorizer.fit_transform(df['texto'])
\end{lstlisting}

A função \texttt{fit\_transform} da classe \texttt{TfidfVectorizer} é o elemento central deste processo. Ela executa duas operações críticas: primeiro, o fit constrói o vocabulário (léxico) a partir do Corpus de notícias, e, simultaneamente, o transform projeta os documentos nesse vocabulário, gerando a matriz numérica de pesos TF-IDF. A remoção de *stop words* em inglês otimiza o espaço vetorial, eliminando ruído linguístico.

\clearpage

\subsection{Função de Busca e Classificação de Resultados}
O núcleo operacional do sistema é a função \texttt{buscar}, responsável por processar a consulta do usuário (query) e retornar os resultados classificados.

\begin{lstlisting}[caption=Função de Busca e Similaridade de Cosseno (tfidf.py), label=lst:search\_function]
# 3. Função de busca
def buscar(query, top_n=5):
    query_vec = vectorizer.transform([query])
    cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()
    indices = cosine_similarities.argsort()[-top_n:][::-1]
    resultados = df.iloc[indices][['id', 'texto']]\
    resultados['similaridade'] = cosine_similarities[indices]
    return resultados
\end{lstlisting}

A função primeiro transforma a query em seu vetor correspondente (\texttt{vectorizer.transform}). Em seguida, o método \texttt{cosine\_similarity} calcula a similaridade angular entre o vetor da consulta e todos os vetores da matriz TF-IDF, gerando uma lista de pontuações de relevância. Os resultados são então ordenados de forma decrescente por essas pontuações e formatados para apresentação final, fornecendo o ranking de relevância.

% -------------------------------
% --- 5. RESULTADOS VISUAIS E DISCUSSÃO ---
% -------------------------------
\section{Resultados e Discussão de Desempenho}

A validação do sistema confirmou a proficiência do modelo vetorial TF-IDF na recuperação da informação, ao converter a complexidade dos dados textuais em resultados de busca quantitativos e ordenados. A análise de desempenho é apresentada em duas frentes: a descrição formal do fluxo de processamento e a discussão dos resultados empíricos de similaridade.

\subsection{Fluxo de Processamento do Sistema}
A Tabela~\ref{tab:etapas_tfidf} detalha as etapas sequenciais e computacionais do processo de vetorização e busca. Esta representação é fundamental por delinear a arquitetura do sistema, desde a ingestão da matéria-prima (Corpus) até a materialização do *ranking* final de notícias.

\begin{table}[H]
\centering
\caption{Tabela 1: Etapas do Processo de Vetorização e Busca TF-IDF}
\begin{tabular}{|c|p{9cm}|c|}
\hline
\textbf{Passo} & \textbf{Descrição do Processo} & \textbf{Fluxo} \\
\hline
1 & Corpus de Dados (\texttt{cripto\_noticias(1).csv}) - Entrada de dados brutos. & $\downarrow$ \\
2 & Pré-Processamento de Texto (Tokenização e Remoção de Stopwords em Inglês) & $\downarrow$ \\
3 & Criação da Matriz TF-IDF (\texttt{vectorizer.fit\_transform}) - Vetorização dos documentos. & $\downarrow$ \\
4 & Entrada da Consulta (\textit{Query}) - Transformação da consulta em vetor TF-IDF. & $\downarrow$ \\
5 & Cálculo da Similaridade de Cosseno (\texttt{cosine\_similarity}) - Comparação entre vetor da *query* e vetores dos documentos. & $\downarrow$ \\
6 & Ranking de Resultados (Notícias ordenadas por pontuação) - Geração da lista final de relevância. & $\downarrow$ \\
7 & Fim do Processo & \hspace{0.5cm} \\
\hline
\end{tabular}
\label{tab:etapas_tfidf}
\end{table}

A arquitetura sequencial exposta na Tabela~\ref{tab:etapas_tfidf} é crucial para o desempenho. O Pré-Processamento (Passo 2) é uma etapa de redução de dimensionalidade e ruído, garantindo que apenas os tokens de maior carga informacional sejam retidos. O Cálculo da Similaridade de Cosseno (Passo 5) atua como a função de recuperação, que traduz a proximidade vetorial (semântica) entre a intenção de busca e o conteúdo das notícias em uma métrica de relevância objetiva, que culmina no ranking final.

\subsection{Análise de Resultados por Similaridade de Cosseno}
Para a comprovação empírica do desempenho, um experimento de busca foi realizado utilizando a query ``regulamentação de stablecoins e compliance''. A Tabela~\ref{tab:similaridade} apresenta os resultados classificados, expondo os trechos mais relevantes e as pontuações de similaridade correspondentes.

\begin{table}[h]
    \centering
    \caption{Tabela 2: Resultados da Busca de Exemplo para a Query: ``regulamentação de stablecoins e compliance''}
    \label{tab:similaridade}
    \begin{tabular}{ccp{9.5cm}} % CORRIGIDO PARA EVITAR CORTE
        \toprule
        \textbf{ID da Notícia} & \textbf{Similaridade} & \textbf{Trecho Fiel ao Corpus} \\
        \midrule
        9 & 0.4579 & O governo dos EUA intensifica discussões sobre regulação das stablecoins... \\
        88 & 0.3201 & Projetos de stablecoins regionais surgem para facilitar comércio local. \\
        3 & 0.2888 & A Binance anunciou novas medidas de conformidade para atender exigências... \\
        96 & 0.2105 & A regulação mais clara atrai investidores institucionais para o setor. \\
        85 & 0.1982 & A regulação cripto avança na América Latina com propostas de transparência... \\
        \bottomrule
    \end{tabular}
\end{table}

A análise da Tabela~\ref{tab:similaridade} fornece evidências robustas da eficácia do modelo TF-IDF. O documento de ID 9 alcança a maior pontuação de similaridade (0.4579), um resultado esperado, visto que o documento contém os termos exatos "regulação" e "stablecoins" em alta densidade, confirmando a precisão lexical do modelo.

O resultado mais significativo reside no documento de ID 3, que obteve uma similaridade considerável (0.2888) sem apresentar correspondência literal aos termos "stablecoins" ou "regulação". Este documento utiliza a palavra-chave "conformidade" que, no contexto financeiro do Corpus, é o equivalente semântico e prático de compliance. Este achado demonstra a capacidade de busca por similaridade temática do algoritmo. Ao ponderar a raridade e o peso de "conformidade" em documentos sobre cripto, o TF-IDF foi capaz de inferir a relevância temática, excedendo a mera correspondência de tokens e validando a abordagem semântica do sistema.

Os resultados subsequentes (IDs 96 e 85) exemplificam a relevância gradativa inerente ao modelo vetorial, abordando o tema mais genérico de "regulação cripto" em um espectro mais amplo, o que justifica sua classificação em posições inferiores e com pontuações progressivamente menores, de acordo com o princípio da proximidade vetorial.

% -------------------------------
% --- 6. CONCLUSÃO ---
% -------------------------------
\section{Conclusão}

O presente estudo resultou na implementação bem-sucedida de um motor de busca semântica fundamentado no modelo TF-IDF, adaptado para um Corpus especializado de notícias de criptomoedas. A validação empírica demonstrou a robustez do sistema na vetorização e na classificação de resultados por Similaridade de Cosseno, comprovando que o TF-IDF constitui uma metodologia eficiente para a Recuperação da Informação em domínios de alta especificidade e dinamismo. A arquitetura de código é aderente aos padrões de engenharia de software (utilizando Pandas e scikit-learn) e o desempenho alcançado valida os objetivos propostos para a recuperação de informações temáticas. Estudos futuros podem explorar a integração de modelos de Word Embeddings para aprimorar a capacidade de inferência semântica para consultas que não possuem correspondência direta no vocabulário.

\clearpage

% -------------------------------
% --- REFERÊNCIAS ---
% -------------------------------
\begin{spacing}{1.0}
\renewcommand{\refname}{Referências}
\addcontentsline{toc}{section}{Referências}

\begin{thebibliography}{9}

\bibitem{almeida2021pln}
ALMEIDA, João Paulo. \textbf{Introdução ao Processamento de Linguagem Natural}. São Paulo: Novatec, 2021.

\bibitem{silva2020mining}
SILVA, Carlos Henrique. \textbf{Mineração de Texto e Recuperação de Informação: Conceitos e Aplicações}. Rio de Janeiro: LTC, 2020.

\bibitem{martins2022tfidf}
MARTINS, Ana Beatriz. Entendendo o TF-IDF: Como os Algoritmos Avaliam a Relevância das Palavras. \textbf{Blog DataHackers}, 2022. Disponível em: \url{https://datahackers.com.br/}. Acesso em: 04 nov. 2025.

\bibitem{oliveira2023busca}
OLIVEIRA, Rafael. Como funciona um motor de busca baseado em TF-IDF e Similaridade de Cosseno. \textbf{Medium}, 2023. Disponível em: \url{https://medium.com/}. Acesso em: 04 nov. 2025.

\bibitem{souza2024pln}
SOUZA, Mariana. Aplicações de Processamento de Linguagem Natural em Projetos de Dados. \textbf{Revista Científica Digital}, v. 8, n. 2, p. 45–58, 2024.

\end{thebibliography}

\end{spacing}

\end{document}